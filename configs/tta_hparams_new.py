import math


def scenario(src_id, trg_id):
    """Normalize场景ID为字符串元组，避免'几to几'写错或类型不一致。"""
    return str(src_id), str(trg_id)

def backbone_scenario(backbone, src_id, trg_id):
    """Helper to tag overrides with a specific backbone while keeping keys hashable."""
    return str(backbone), str(src_id), str(trg_id)


HAR_ACCUP_SCENARIO_OVERRIDES = {
    backbone_scenario('CNN', 6, 23): {
        'batch_size': 16,
        'd_margin': 0.08534362035041929,
        'e_margin_scale': 0.7805454236248349,
        'filter_K': 25,
        'fisher_alpha': 2934.1037826413212,
        'freeze_bn_stats': False,
        'grad_clip': 1.2644438589281592,
        'grad_clip_value': 1.0,
        'include_warmup_support': True,
        'lambda_eata': 0.7988708550941633,
        'learning_rate': 7.5387503283681256e-06,
        'lr_decay': 0.340771999392971,
        'max_fisher_updates': 128,
        'memory_size': 3584,
        'momentum': 0.9623886820116638,
        'num_epochs': 20,
        'online_fisher': True,
        'pre_learning_rate': 0.00025717468417589724,
        'quantile': 0.39644741678884826,
        'safety_keep_frac': 0.7657402683821652,
        'step_size': 64,
        'steps': 2,
        'tau': 25,
        'temperature': 1.5577680012014463,
        'train_backbone_modules': None,
        'train_classifier': True,
        'train_full_backbone': True,
        'use_eata_reg': True,
        'use_eata_select': True,
        'use_quantile': True,
        'warmup_min': 199,
        'weight_decay': 0.0001383791369728026,
    },

    backbone_scenario('CNN', 7, 13): {
        'num_epochs': 15,
        'batch_size': 30,
        'weight_decay': 3e-4,
        'step_size': 100,
        'lr_decay': 1.0,
        'steps': 1,

        # 选样/温度
        'use_eata_select': True,
        'use_quantile': True,  # 你日志里还是 False，改成 True 才会有 q25
        'quantile': 0.25,
        'temperature': 1.0,  # 1.2 -> 1.0，避免人为抬高熵
        'tau': 5,  # 10 -> 5，增强对比信号

        # 训练范围（只动少量层）
        'train_full_backbone': False,
        'train_backbone_modules': ['conv_block1', 'conv_block2'],  # 或你的 BN 模块名
        'train_classifier': True,
        'freeze_bn_stats': True,

        # Fisher
        'online_fisher': True,
        'fisher_alpha': 300,  # 500 -> 300，更“软”的约束
        'max_fisher_updates': 32,

        # 原型/支持集
        'include_warmup_support': True,
        'warmup_min': 50,  # 150 -> 50，让支持集更早刷新
        'filter_K': 32,
        'safety_keep_frac': 0.35,
        'memory_size': 2048,

        # 优化/裁剪（TTA 用）
        'learning_rate': 3e-5,  # 只作为TTA lr；不去动源域训练的 lr
        'grad_clip': 1.0,
        'grad_clip_value': None,
    },


    backbone_scenario('CNN', 9, 18): {
        'batch_size': 16,
        'd_margin': 0.07980904165901534,
        'e_margin_scale': 0.8878387961263575,
        'filter_K': 25,
        'fisher_alpha': 2220.324902484645,
        'freeze_bn_stats': False,
        'grad_clip': 0.8356782014410484,
        'grad_clip_value': 0.1,
        'include_warmup_support': True,
        'lambda_eata': 1.1268757877559819,
        'learning_rate': 1.606218436522357e-05,
        'lr_decay': 0.5376889797367629,
        'max_fisher_updates': 128,
        'memory_size': 3840,
        'momentum': 0.7804898219901741,
        'num_epochs': 17,
        'online_fisher': True,
        'pre_learning_rate': 0.0003310150094839371,
        'quantile': 0.2155466758233468,
        'safety_keep_frac': 0.7190883924895702,
        'step_size': 58,
        'steps': 1,
        'tau': 16,
        'temperature': 2.670981843899618,
        'train_backbone_modules': None,
        'train_classifier': True,
        'train_full_backbone': True,
        'use_eata_reg': True,
        'use_eata_select': True,
        'use_quantile': True,
        'warmup_min': 222,
        'weight_decay': 0.0006453417651719701,
    },

    backbone_scenario('CNN', 12, 16): {
        'batch_size': 16,
        'd_margin': 0.09077515198254811,
        'e_margin_scale': 0.6832953329309684,
        'filter_K': 29,
        'fisher_alpha': 3109.3892312984212,
        'freeze_bn_stats': False,
        'grad_clip': 0.5998673721044714,
        'grad_clip_value': 0.5,
        'include_warmup_support': True,
        'lambda_eata': 2.040311908806854,
        'learning_rate': 4.311017839534308e-06,
        'lr_decay': 0.66398919635364,
        'max_fisher_updates': 128,
        'memory_size': 3584,
        'momentum': 0.955116122501502,
        'num_epochs': 14,
        'online_fisher': True,
        'pre_learning_rate': 0.00026572007156055067,
        'quantile': 0.46322930742774093,
        'safety_keep_frac': 0.36736563550837187,
        'step_size': 67,
        'steps': 2,
        'tau': 24,
        'temperature': 1.2562368051574477,
        'train_backbone_modules': None,
        'train_classifier': True,
        'train_full_backbone': True,
        'use_eata_reg': True,
        'use_eata_select': True,
        'use_quantile': True,
        'warmup_min': 199,
        'weight_decay': 3.876223925704905e-05,
    },

    backbone_scenario('TimesNet', 6, 23): {
        'batch_size': 24,
        'd_margin': 0.08165903318753484,
        'e_margin_scale': 0.2653831388363226,
        'filter_K': 15,
        'fisher_alpha': 7376.533105885332,
        'freeze_bn_stats': False,
        'grad_clip': 0.6006326577826228,
        'grad_clip_value': None,
        'lambda_eata': 0.6537639460051092,
        'learning_rate': 5.29132514451458e-05,
        'lr_decay': 0.33958648479935305,
        'max_fisher_updates': 256,
        'memory_size': 3584,
        'momentum': 0.7575890008976107,
        'num_epochs': 21,
        'pre_learning_rate': 8.599954834769283e-05,
        'quantile': 0.6378167244134885,
        'safety_keep_frac': 0.20393571365397273,
        'step_size': 26,
        'steps': 1,
        'tau': 9,
        'temperature': 2.244838911198617,
        'times_dropout': 0.18029693777110922,
        'times_ffn_expansion': 2.8890157568389685,
        'times_hidden_channels': 96,
        'times_num_layers': 3,
        'times_patch_lens': [4, 8],
        'train_backbone_modules': None,
        'use_quantile': False,
        'warmup_min': 292,
        'weight_decay': 0.00010347980607367024,
    },

    backbone_scenario('TimesNet', 7, 13): {
        'batch_size': 24,
        'd_margin': 0.046399409912106435,
        'e_margin_scale': 0.31524566855245756,
        'filter_K': 21,
        'fisher_alpha': 4181.249625381953,
        'freeze_bn_stats': True,
        'grad_clip': 0.236565687207476,
        'grad_clip_value': 0.1,
        'lambda_eata': 1.7654162133997904,
        'learning_rate': 4.01855926308842e-05,
        'lr_decay': 0.4500011347014487,
        'max_fisher_updates': 512,
        'memory_size': 768,
        'momentum': 0.8567668738798108,
        'num_epochs': 10,
        'pre_learning_rate': 0.0004679651858931064,
        'quantile': 0.5669757500511252,
        'safety_keep_frac': 0.40826473109471,
        'step_size': 47,
        'steps': 3,
        'tau': 9,
        'temperature': 0.8245334694212887,
        'times_dropout': 0.20900859132251698,
        'times_ffn_expansion': 3.591058099301806,
        'times_hidden_channels': 256,
        'times_num_layers': 5,
        'times_patch_lens': [24, 58, 64],
        'train_backbone_modules': ['conv_block1'],
        'use_quantile': True,
        'warmup_min': 91,
        'weight_decay': 0.0004116588319118168,
    },

    backbone_scenario('TimesNet', 9, 18): {
        'batch_size': 16,
        'd_margin': 0.1172737939601941,
        'e_margin_scale': 0.5010204183028295,
        'filter_K': 5,
        'fisher_alpha': 6653.952284344285,
        'freeze_bn_stats': False,
        'grad_clip': 0.12489883474970467,
        'grad_clip_value': 0.05,
        'lambda_eata': 2.087162749053059,
        'learning_rate': 0.00024473604033011887,
        'lr_decay': 0.3273683141632288,
        'max_fisher_updates': 32,
        'memory_size': 3584,
        'momentum': 0.781906222400651,
        'num_epochs': 20,
        'pre_learning_rate': 0.0001578704047559943,
        'quantile': 0.3579679602239242,
        'safety_keep_frac': 0.34203868110806523,
        'step_size': 48,
        'steps': 2,
        'tau': 17,
        'temperature': 1.4020127623650438,
        'times_dropout': 0.21408149112125802,
        'times_ffn_expansion': 2.7730672879750857,
        'times_hidden_channels': 160,
        'times_num_layers': 4,
        'times_patch_lens': [4, 7, 12],
        'train_backbone_modules': None,
        'use_quantile': True,
        'warmup_min': 227,
        'weight_decay': 0.0008927317001886844,
    },

    backbone_scenario('TimesNet', 12, 16): {
        'batch_size': 16,
        'd_margin': 0.013597773868984857,
        'e_margin_scale': 0.8021670869953759,
        'filter_K': 15,
        'fisher_alpha': 5727.224802005052,
        'freeze_bn_stats': False,
        'grad_clip': 0.5459033999122532,
        'grad_clip_value': 1.0,
        'lambda_eata': 1.5278788974673312,
        'learning_rate': 0.00011855414199157462,
        'lr_decay': 0.5176043436389376,
        'max_fisher_updates': 128,
        'memory_size': 3584,
        'momentum': 0.79399931072531,
        'num_epochs': 22,
        'pre_learning_rate': 0.0004976352270890752,
        'quantile': 0.6132448627521127,
        'safety_keep_frac': 0.7735797480078278,
        'step_size': 25,
        'steps': 3,
        'tau': 22,
        'temperature': 1.9559925486980083,
        'times_dropout': 0.2335843952130982,
        'times_ffn_expansion': 2.542879893363831,
        'times_hidden_channels': 224,
        'times_num_layers': 4,
        'times_patch_lens': [48, 64],
        'train_backbone_modules': None,
        'use_quantile': False,
        'warmup_min': 182,
        'weight_decay': 0.00033697585011473397,
    },
}

FD_ACCUP_SCENARIO_OVERRIDES = {
    backbone_scenario('CNN', 0, 1): {
        'batch_size': 144,
        'd_margin': 0.0183863375321855,
        'e_margin_scale': 0.47811464033707163,
        'filter_K': 7,
        'fisher_alpha': 7028.314560778086,
        'freeze_bn_stats': True,
        'grad_clip': 0.26628882606993365,
        'grad_clip_value': 0.1,
        'lambda_eata': 2.044349638056334,
        'learning_rate': 0.0003207739745068943,
        'lr_decay': 0.7094095270177913,
        'max_fisher_updates': 64,
        'memory_size': 4096,
        'momentum': 0.7866467109569028,
        'num_epochs': 52,
        'pre_learning_rate': 0.000498249004268351,
        'quantile': 0.19510601887927123,
        'safety_keep_frac': 0.31528276154207074,
        'step_size': 33,
        'steps': 5,
        'tau': 16,
        'temperature': 1.592710809505369,
        'train_backbone_modules': None,
        'use_quantile': True,
        'warmup_min': 309,
        'weight_decay': 0.00021386356389740106,
    },

    backbone_scenario('CNN', 1, 0): {
        'batch_size': 152,
        'd_margin': 0.14815022485412382,
        'e_margin_scale': 0.8166117775876512,
        'filter_K': 23,
        'fisher_alpha': 8984.74278985258,
        'freeze_bn_stats': True,
        'grad_clip': 0.6698939876628116,
        'grad_clip_value': None,
        'lambda_eata': 1.0371031536778468,
        'learning_rate': 0.0003017439444728125,
        'lr_decay': 0.38294676698414776,
        'max_fisher_updates': 32,
        'memory_size': 2048,
        'momentum': 0.6332259663110997,
        'num_epochs': 38,
        'pre_learning_rate': 6.949336258981423e-05,
        'quantile': 0.8775550522596002,
        'safety_keep_frac': 0.36743978604199884,
        'step_size': 33,
        'steps': 2,
        'tau': 11,
        'temperature': 2.813562110835087,
        'train_backbone_modules': ['conv_block1'],
        'use_quantile': False,
        'warmup_min': 315,
        'weight_decay': 1.448523221986509e-05,
    },

    backbone_scenario('CNN', 1, 2): {
        'batch_size': 72,
        'd_margin': 0.006920002717270326,
        'e_margin_scale': 0.45149112490537,
        'filter_K': 21,
        'fisher_alpha': 5478.022362331467,
        'freeze_bn_stats': False,
        'grad_clip': 0.6412897988425508,
        'grad_clip_value': 1.0,
        'lambda_eata': 1.403840569141184,
        'learning_rate': 3.172541223912814e-05,
        'lr_decay': 0.615464555646038,
        'max_fisher_updates': 32,
        'memory_size': 3840,
        'momentum': 0.7257951979387711,
        'num_epochs': 60,
        'pre_learning_rate': 8.284974324314706e-05,
        'quantile': 0.5835101086722418,
        'safety_keep_frac': 0.7840712382018171,
        'step_size': 42,
        'steps': 1,
        'tau': 15,
        'temperature': 0.3681560052150252,
        'train_backbone_modules': None,
        'use_quantile': False,
        'warmup_min': 118,
        'weight_decay': 1.1460879246850117e-05,
    },

    backbone_scenario('CNN', 2, 3): {
        'batch_size': 136,
        'd_margin': 0.1148028367542925,
        'e_margin_scale': 0.2711419841905244,
        'filter_K': 31,
        'fisher_alpha': 4718.084437636164,
        'freeze_bn_stats': False,
        'grad_clip': 0.4315576856108949,
        'grad_clip_value': 0.5,
        'lambda_eata': 1.1494392724026496,
        'learning_rate': 1.2669071187801276e-05,
        'lr_decay': 0.7398434773645458,
        'max_fisher_updates': 1024,
        'memory_size': 3328,
        'momentum': 0.8691053978217602,
        'num_epochs': 53,
        'pre_learning_rate': 0.0004955657433737235,
        'quantile': 0.42235704540544017,
        'safety_keep_frac': 0.7421546921323318,
        'step_size': 24,
        'steps': 2,
        'tau': 7,
        'temperature': 2.0365044223128925,
        'train_backbone_modules': None,
        'use_quantile': False,
        'warmup_min': 224,
        'weight_decay': 0.0001966538456566406,
    },

    backbone_scenario('CNN', 3, 1): {
        'batch_size': 136,
        'd_margin': 0.0012656594511584046,
        'e_margin_scale': 0.7601492804386671,
        'filter_K': 7,
        'fisher_alpha': 6711.726571973501,
        'freeze_bn_stats': False,
        'grad_clip': 0.9701184936746179,
        'grad_clip_value': None,
        'lambda_eata': 2.429306357105021,
        'learning_rate': 7.339025206534731e-05,
        'lr_decay': 0.6243348014728303,
        'max_fisher_updates': 128,
        'memory_size': 2048,
        'momentum': 0.6900848905198135,
        'num_epochs': 43,
        'pre_learning_rate': 0.00024623238843760265,
        'quantile': 0.4206683097773644,
        'safety_keep_frac': 0.19608361422993542,
        'step_size': 23,
        'steps': 2,
        'tau': 5,
        'temperature': 0.6478374488847998,
        'train_backbone_modules': ['conv_block1'],
        'use_quantile': True,
        'warmup_min': 56,
        'weight_decay': 4.959043637552348e-05,
    },
}

EEG_ACCUP_SCENARIO_OVERRIDES = {
    backbone_scenario('CNN', 0, 11): {
        'num_epochs': 30,
        'batch_size': 128,        # ↑ 从 64 提到 96：更稳定的 BN/统计，CPU 也扛得住
        'weight_decay': 5e-5,
        'step_size': 10,         # ↓ 让预训练在第20轮衰减一次学习率
        'lr_decay': 0.5,
        'steps': 1,
        'momentum': 0.6,

        # ——选样/温度：先收紧——
        'use_eata_select': True,
        'use_quantile': True,
        'quantile': 0.10,  # 保持，但让它“真的生效”
        'temperature': 0.9,  # 2.699 -> 1.0，整体降熵
        'e_margin_scale': 0.30,  # 0.5108 -> 0.40，使 base≈ln(5)*0.40≈0.64
        'tau': 8,  # 26 -> 8，增强对比梯度

        # ——训练范围：只动少量层——
        'train_full_backbone': False,
        'train_backbone_modules': ['conv_block1', 'conv_block2'],  # 只调 BN 仿射
        'train_classifier': True,
        'freeze_bn_stats': True,  # EEG 上先稳住统计量

        # ——Fisher：软一些——
        'online_fisher': True,
        'fisher_alpha': 1000,  # 7895 -> 1500
        'max_fisher_updates': 256,  # 1024 -> 256

        # ——原型/支持集：更积极刷新——
        'include_warmup_support': True,
        'warmup_min': 64,  # 保持大致两批后开始
        'filter_K': 18,  # 7 -> 15（按类配额）
        'safety_keep_frac': 0.30,  # 0.628 -> 0.35

        # ——优化/裁剪（TTA 用）——
        'learning_rate': 3e-5,  # 9.0e-5 -> 3e-5（可训练层少，LR 也要降）
        'grad_clip': 0.8,  # 0.566 -> 0.8
        'grad_clip_value': None,  # 取消元素级裁剪（容易把梯度“拍扁”）
    },


    backbone_scenario('CNN', 7, 18): {
        'batch_size': 128,
        'd_margin': 0.07034442316377004,
        'e_margin_scale': 0.5489757739417829,
        'filter_K': 21,
        'fisher_alpha': 1500,
        'freeze_bn_stats': True,
        'grad_clip': 0.6,
        'grad_clip_value': None,
        'lambda_eata': 1.560838942707314,
        'learning_rate': 7.921067220074702e-05,
        'lr_decay': 0.67224375631797,
        'max_fisher_updates': 512,
        'memory_size': 3328,
        'momentum': 0.7967429567554412,
        'num_epochs': 30,
        'pre_learning_rate': 0.00025294216070997867,
        'quantile': 0.25,
        'safety_keep_frac': 0.30,
        'step_size': 22,
        'steps': 5,
        'tau': 24,
        'temperature': 1.0,
        'train_backbone_modules': None,
        'use_quantile': True,
        'warmup_min': 70,
        'weight_decay': 1.384398473343541e-05,
    },

    backbone_scenario('CNN', 9, 14): {
        'batch_size': 200,
        'd_margin': 0.05805391012154483,
        'e_margin_scale': 0.55,
        'filter_K': 15,
        'fisher_alpha': 900,
        'freeze_bn_stats': True,
        'grad_clip': 0.8,
        'grad_clip_value': None,
        'lambda_eata': 1.732693370751086,
        'learning_rate': 6.64567486281664e-05,
        'lr_decay': 0.5338753097097609,
        'max_fisher_updates': 256,
        'memory_size': 2048,
        'momentum': 0.9794323471899682,
        'num_epochs': 25,
        'pre_learning_rate': 0.0004995175766702046,
        'quantile': 0.30,
        'safety_keep_frac': 0.5250050659384953,
        'step_size': 30,
        'steps': 2,
        'tau': 13,
        'temperature': 1.0,
        'train_full_backbone': False,
        'train_backbone_modules': ['conv_block1', 'conv_block2'],  # 只调 BN 仿射
        'train_classifier': True,
        'use_quantile': True,
        'warmup_min': 170,
        'weight_decay': 4.395625457432446e-05,
        'include_warmup_support': True,
    },

    backbone_scenario('CNN', 12, 5): {
        'batch_size': 90,
        'd_margin': 0.06327217957578415,
        'e_margin_scale': 0.40,
        'filter_K': 21,
        'fisher_alpha': 1200,
        'freeze_bn_stats': True,
        'grad_clip': 0.6367227475236301,
        'grad_clip_value': 0.1,
        'lambda_eata': 1.7877750308800844,
        'learning_rate': 0.00013489103307438513,
        'lr_decay': 0.4900773686888742,
        'max_fisher_updates': 256,
        'memory_size': 3840,
        'momentum': 0.8910421866333144,
        'num_epochs': 34,
        'pre_learning_rate': 0.0003576952899015023,
        'quantile': 0.30,
        'safety_keep_frac': 0.08412994435207588,
        'step_size': 25,
        'steps': 1,
        'tau': 18,
        'temperature': 2.0,
        'train_full_backbone': False,
        'train_backbone_modules': ['conv_block1', 'conv_block2'],  # 只调 BN 仿射
        'train_classifier': True,
        'use_quantile': True,
        'warmup_min': 96,
        'weight_decay': 6.192854881429892e-05,
        'include_warmup_support': True,
    },

    backbone_scenario('CNN', 16, 1): {
        'batch_size': 80,
        'd_margin': 0.04465755173613134,
        'e_margin_scale': 0.7057197246282505,
        'filter_K': 4,
        'fisher_alpha': 1000,
        'freeze_bn_stats': True,
        'grad_clip': 0.5829788587860735,
        'grad_clip_value': 0.1,
        'lambda_eata': 1.3314323308399154,
        'learning_rate': 0.0004943260953204557,
        'lr_decay': 0.6947511865510675,
        'max_fisher_updates': 256,
        'memory_size': 2560,
        'momentum': 0.8079469220282296,
        'num_epochs': 40,
        'pre_learning_rate': 0.00047104669927932734,
        'quantile': 0.60,
        'safety_keep_frac': 0.09984190941199379,
        'step_size': 15,
        'steps': 4,
        'tau': 10,
        'temperature': 1.521640273730759,
        'train_full_backbone': False,
        'train_backbone_modules': ['conv_block1', 'conv_block2'],  # 只调 BN 仿射
        'train_classifier': True,
        'use_quantile': False,
        'warmup_min': 64,
        'weight_decay': 2.0322884602495502e-05,
        'include_warmup_support': True,
    },

    backbone_scenario('TimesNet', 0, 11): {
        'batch_size': 56,
        'd_margin': 0.02525041340256418,
        'e_margin_scale': 0.8068803885522062,
        'filter_K': 15,
        'fisher_alpha': 4928.290760909347,
        'freeze_bn_stats': False,
        'grad_clip': 0.7214969432379201,
        'grad_clip_value': None,
        'lambda_eata': 0.5194891859636153,
        'learning_rate': 0.000149373266918428,
        'lr_decay': 0.7479391097085422,
        'max_fisher_updates': 1024,
        'memory_size': 2816,
        'momentum': 0.7985101019968879,
        'num_epochs': 29,
        'pre_learning_rate': 1.6640648676342462e-05,
        'quantile': 0.5014383567697188,
        'safety_keep_frac': 0.5345715688890845,
        'step_size': 17,
        'steps': 2,
        'tau': 6,
        'temperature': 2.7091374083713156,
        'times_dropout': 0.21631311407709936,
        'times_ffn_expansion': 1.4132644920302384,
        'times_hidden_channels': 96,
        'times_num_layers': 6,
        'times_patch_lens': [64, 159],
        'train_backbone_modules': ['conv_block1'],
        'use_quantile': False,
        'warmup_min': 35,
        'weight_decay': 6.099237092693815e-05,
    },

    scenario(0, 11): {
        'd_margin': 0.13809420076977189,
        'e_margin_scale': 0.8675286976378526,
        'filter_K': 13,
        'filter_K_bn_only': 13,
        'fisher_alpha': 2425.599851216968,
        'freeze_bn_stats_bn_only': True,
        'grad_clip': 0.2978930706551386,
        'grad_clip_bn_only': 0.2978930706551386,
        'grad_clip_value': 0.1,
        'grad_clip_value_bn_only': 0.1,
        'lambda_eata': 1.9022948836924023,
        'learning_rate': 0.00010133453612043214,
        'max_fisher_updates': -1,
        'memory_size': 3584,
        'pre_learning_rate': 0.0004958066715039774,
        'quantile': 0.2529354283324555,
        'safety_keep_frac': 0.337384307833167,
        'safety_keep_frac_bn_only': 0.337384307833167,
        'tau': 25,
        'temperature': 2.914722920741117,
        'times_dropout': 0.07246761783144418,
        'times_ffn_expansion': 2.6790973501683997,
        'times_hidden_channels': 256,
        'times_num_layers': 4,
        'times_patch_base': 16,
        'times_patch_count': 4,
        'times_patch_scale': 1.8665391607957145,
        'train_scope': 'bn_only',
        'use_quantile': True,
        'warmup_min': 205,
    },

    scenario(7, 18): {
        'd_margin': 0.10293557930545941,
        'e_margin_scale': 0.6894333998182214,
        'filter_K': 5,
        'filter_K_bn_only': 5,
        'fisher_alpha': 1504.328161917314,
        'freeze_bn_stats_bn_only': True,
        'grad_clip': 0.15178133412554715,
        'grad_clip_bn_only': 0.15178133412554715,
        'grad_clip_value': None,
        'grad_clip_value_bn_only': None,
        'lambda_eata': 0.566842805225137,
        'learning_rate': 0.00012347528062767586,
        'max_fisher_updates': 256,
        'memory_size': 4096,
        'pre_learning_rate': 0.00013158557340444023,
        'quantile': 0.14167042020635323,
        'safety_keep_frac': 0.17911779868354522,
        'safety_keep_frac_bn_only': 0.17911779868354522,
        'tau': 18,
        'temperature': 2.11361357557397,
        'times_dropout': 0.23114491509075497,
        'times_ffn_expansion': 1.3038719409562929,
        'times_hidden_channels': 256,
        'times_num_layers': 3,
        'times_patch_base': 96,
        'times_patch_count': 4,
        'times_patch_scale': 1.3303717842798888,
        'train_scope': 'bn_only',
        'use_quantile': True,
        'warmup_min': 30,
    },

    scenario(9, 14): {
        'd_margin': 0.018365476145257163,
        'e_margin_scale': 0.7625502822020727,
        'filter_K': 19,
        'filter_K_partial': 19,
        'fisher_alpha': 5609.55348418654,
        'freeze_bn_stats_partial': False,
        'grad_clip': 0.7677470739699619,
        'grad_clip_partial': 0.7677470739699619,
        'grad_clip_value': 0.25,
        'grad_clip_value_partial': 0.25,
        'lambda_eata': 1.7037085189188386,
        'learning_rate': 1.0122614999144783e-05,
        'max_fisher_updates': -1,
        'memory_size': 1280,
        'partial_module_bundle': 'conv12',
        'pre_learning_rate': 0.0004827670468678035,
        'quantile': 0.2252314614805666,
        'safety_keep_frac': 0.36409531702704145,
        'safety_keep_frac_partial': 0.36409531702704145,
        'tau': 24,
        'temperature': 2.590079127893502,
        'times_dropout': 0.2487702914866347,
        'times_ffn_expansion': 1.6822492900189818,
        'times_hidden_channels': 160,
        'times_num_layers': 2,
        'times_patch_base': 72,
        'times_patch_count': 3,
        'times_patch_scale': 1.4928123091088987,
        'train_classifier_partial': False,
        'train_scope': 'partial',
        'use_quantile': False,
        'warmup_min': 43,
    },

    scenario(12, 5): {
        'batch_size': 88,
        'd_margin': 0.050108522682583985,
        'e_margin_scale': 0.4456162543895605,
        'filter_K': 9,
        'fisher_alpha': 1776.7407957592718,
        'freeze_bn_stats': True,
        'grad_clip': 0.2587599113991441,
        'grad_clip_value': 0.05,
        'lambda_eata': 0.7421164696840489,
        'learning_rate': 1.0000318430740127e-05,
        'lr_decay': 0.6433162091238267,
        'max_fisher_updates': 32,
        'memory_size': 1024,
        'momentum': 0.8008310363555619,
        'num_epochs': 43,
        'pre_learning_rate': 0.00012483102695352874,
        'quantile': 0.8808501320114017,
        'safety_keep_frac': 0.19080553145716495,
        'step_size': 26,
        'steps': 1,
        'tau': 25,
        'temperature': 2.0824090570211613,
        'use_quantile': False,
        'warmup_min': 115,
        'weight_decay': 6.540132883420885e-06,
    },

    scenario(16, 1): {
        'batch_size': 96,
        'd_margin': 0.018453418040454875,
        'e_margin_scale': 0.376553345269517,
        'filter_K': 11,
        'fisher_alpha': 3976.767190034433,
        'freeze_bn_stats': True,
        'grad_clip': 0.19102411062144053,
        'grad_clip_value': 0.05,
        'lambda_eata': 0.6465185555231232,
        'learning_rate': 1.3831057852051844e-05,
        'lr_decay': 0.7499042383693464,
        'max_fisher_updates': 32,
        'memory_size': 1792,
        'momentum': 0.8726447565477226,
        'num_epochs': 50,
        'pre_learning_rate': 9.004343447348951e-05,
        'quantile': 0.7083294529196547,
        'safety_keep_frac': 0.37450280132071784,
        'step_size': 22,
        'steps': 1,
        'tau': 22,
        'temperature': 2.834073106046921,
        'use_quantile': False,
        'warmup_min': 142,
        'weight_decay': 5.461937405940922e-06,
    },
}

def get_hparams_class(dataset_name):  # 根据给定数据集名称字符串返回对应的数据集配置类
    if dataset_name not in globals():
        raise NotImplementedError("Dataset not found: {}".format(dataset_name))
    return globals()[dataset_name]

class FD():
    def __init__(self):
        super(FD, self).__init__()
        self.train_params = {
            'num_epochs': 40,
            'batch_size': 128,
            'weight_decay': 1e-4,
            'step_size': 30,
            'lr_decay': 0.5,
            'steps': 1,
            'optim_method': 'adam',
            'momentum': 0.9,
            'grad_clip': 0.5,
            'grad_clip_value': None
        }
        self.alg_hparams = {
            'ACCUP': {
                'pre_learning_rate': 3e-4,
                'learning_rate': 1e-4,
                'filter_K': 21,
                'tau': 12,
                'temperature': 0.60,
                'warmup_min': 128,
                'quantile': 0.85,
                'safety_keep_frac': 0.08,

                # EATA
                'e_margin_scale': 0.40,
                'd_margin': 0.02,
                'lambda_eata': 1.4,
                'memory_size': 4096,
                'use_quantile': True,
                'fisher_alpha': 2000.0,
                'max_fisher_updates': -1,
                'freeze_bn_stats': False,

                'scenario_overrides': dict(FD_ACCUP_SCENARIO_OVERRIDES),

                'grad_clip': 0.5,
                'grad_clip_value': None
            },
            'NoAdap': {'pre_learning_rate': 5e-4}
        }

class EEG():
    def __init__(self):
        super(EEG, self).__init__()
        self.train_params = {
            'num_epochs': 40,
            'batch_size': 96,        # ↑ 从 64 提到 96：更稳定的 BN/统计，CPU 也扛得住
            'weight_decay': 5e-5,
            'step_size': 20,         # ↓ 让预训练在第20轮衰减一次学习率
            'lr_decay': 0.5,
            'steps': 1,
            'optim_method': 'adam',
            'momentum': 0.9,
            'grad_clip': 0.5,        # ↑ 统一为 0.5，避免双处设置相互打架
            'grad_clip_value': None
        }
        self.alg_hparams = {
            'ACCUP': {
                'pre_learning_rate': 5e-4,
                'learning_rate': 3e-4,
                'filter_K': 25,
                'tau': 10,
                'temperature': 0.70,
                'warmup_min': 48,
                'quantile': 0.75,
                'safety_keep_frac': 0.30,

                # EATA
                'e_margin_scale': 0.45,
                'd_margin': 0.06,
                'lambda_eata': 1.4,
                'memory_size': 2048,
                'use_quantile': True,
                'fisher_alpha': 2000.0,
                'max_fisher_updates': -1,
                'freeze_bn_stats': False,

                'scenario_overrides': dict(EEG_ACCUP_SCENARIO_OVERRIDES),

                'grad_clip': 0.5,
                'grad_clip_value': None
            },
            'NoAdap': {'pre_learning_rate': 5e-4}
        }


class HAR():
    def __init__(self):
        super(HAR, self).__init__()
        self.train_params = {
            'num_epochs': 15,  # 30 -> 16（避免源域过拟合，利于 TTA）
            'batch_size': 16,
            'weight_decay': 1e-4,
            'step_size': 50,
            'lr_decay': 0.5,
            'steps': 1,
            'optim_method': 'adam',
            'momentum': 0.9,
            'grad_clip': 0.1,
            'grad_clip_value': None
        }
        # 关键：加入 EATA 的开关和超参
        self.alg_hparams = {
            'ACCUP': {
                'pre_learning_rate': 5e-4,
                'learning_rate': 3e-5,  # TTA 基础 lr；如果代码支持分组，BN 用 5e-5
                'filter_K': 10,  # 7 -> 9，密度估计更稳
                'tau': 20,
                'temperature': 2.0,  # 0.6 -> 0.55，略锐化

                # EATA
                'e_margin_scale': 0.70,  # 0.35 -> 0.30，放宽
                'd_margin': 0.05,
                'lambda_eata': 1.0,
                'warmup_min': 24,
                'quantile': 0.90,
                'safety_keep_frac': 0.65,  # 0.4 -> 0.5，保底更多
                'memory_size': 4096,
                'use_quantile': True,
                'fisher_alpha': 2000.0,
                'max_fisher_updates': -1,
                'freeze_bn_stats': False,

                'scenario_overrides': dict(HAR_ACCUP_SCENARIO_OVERRIDES),

                'grad_clip': 1.0,
                'grad_clip_value': 0.5
            },
            'NoAdap': {'pre_learning_rate': 1e-3}
        }

